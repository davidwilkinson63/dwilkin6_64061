{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "A case study using iris dataset for KNN algorithm"
      ],
      "metadata": {
        "id": "bca1ZpDIsGD6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "gwk6dOM0E8Od",
        "outputId": "a44843ac-dbbb-4b02-dc83-43004d89775c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions from the classifier:\n",
            "[0 1 2 0 2 0 1 1 0 1 1 0 0 0 0 0 0 0 2 0 2 1 1 1 0 2 1 1 2 0 2 0 2 1 2 2 1\n",
            " 1 1 2 2 0 2 2 0 1 0 2 2 0 1 1 0 0 1 1 1 1 2 1 2 0 0 1 1 2 0 2 1 0 2 2 1 2\n",
            " 2 0 0 2 1 1 2 0 1 1 0 1 1 2 2 1 0 2 0 2 0 0 1 2 2 1 2 2 0 1 1 0 2 2 2 1 2\n",
            " 2 2 0 0 1 0 2 2 1]\n",
            "Target values:\n",
            "[0 1 2 0 2 0 1 1 0 1 1 0 0 0 0 0 0 0 2 0 2 1 1 1 0 2 1 1 2 0 2 0 2 2 2 2 1\n",
            " 1 1 1 2 0 2 2 0 1 0 2 2 0 1 1 0 0 1 1 1 1 2 1 2 0 0 1 1 1 0 2 1 0 2 2 1 2\n",
            " 2 0 0 2 1 1 2 0 1 1 0 1 1 2 2 1 0 2 0 2 0 0 1 2 2 1 2 2 0 1 1 0 2 2 2 1 2\n",
            " 2 2 0 0 1 0 2 2 1]\n",
            "0.975\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ],
      "source": [
        "# import modules for this project\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load iris dataset\n",
        "iris = datasets.load_iris()\n",
        "data, labels = iris.data, iris.target\n",
        "\n",
        "# training testing split\n",
        "res = train_test_split(data, labels,\n",
        "                       train_size=0.8,\n",
        "                       test_size=0.2,\n",
        "                       random_state=12)\n",
        "train_data, test_data, train_labels, test_labels = res\n",
        "\n",
        "# Create and fit a nearest-neighbor classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# classifier \"out of the box\", no parameters\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(train_data, train_labels)\n",
        "\n",
        "# print some interested metrics\n",
        "print(\"Predictions from the classifier:\")\n",
        "learn_data_predicted = knn.predict(train_data)\n",
        "print(learn_data_predicted)\n",
        "print(\"Target values:\")\n",
        "print(train_labels)\n",
        "print(accuracy_score(learn_data_predicted, train_labels))\n",
        "\n",
        "# re-do KNN using some specific parameters.\n",
        "knn2 = KNeighborsClassifier(algorithm='auto',\n",
        "                            leaf_size=30,\n",
        "                            metric='minkowski',\n",
        "                            p=3,         # p=2 is equivalent to euclidian distance\n",
        "                            metric_params=None,\n",
        "                            n_jobs=1,\n",
        "                            n_neighbors=5,\n",
        "                            weights='uniform')\n",
        "\n",
        "knn.fit(train_data, train_labels)\n",
        "test_data_predicted = knn.predict(test_data)\n",
        "accuracy_score(test_data_predicted, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this command to help with choice of paramters in the `KNeighborsClassifier` function."
      ],
      "metadata": {
        "id": "EGCbBcE5v3Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(KNeighborsClassifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PdlZEmKmcyPN",
        "outputId": "6ae239fc-0bd2-4a6c-cb6c-f5a6a4e0c73b"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class KNeighborsClassifier in module sklearn.neighbors._classification:\n",
            "\n",
            "class KNeighborsClassifier(sklearn.neighbors._base.KNeighborsMixin, sklearn.base.ClassifierMixin, sklearn.neighbors._base.NeighborsBase)\n",
            " |  KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
            " |\n",
            " |  Classifier implementing the k-nearest neighbors vote.\n",
            " |\n",
            " |  Read more in the :ref:`User Guide <classification>`.\n",
            " |\n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  n_neighbors : int, default=5\n",
            " |      Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
            " |\n",
            " |  weights : {'uniform', 'distance'}, callable or None, default='uniform'\n",
            " |      Weight function used in prediction.  Possible values:\n",
            " |\n",
            " |      - 'uniform' : uniform weights.  All points in each neighborhood\n",
            " |        are weighted equally.\n",
            " |      - 'distance' : weight points by the inverse of their distance.\n",
            " |        in this case, closer neighbors of a query point will have a\n",
            " |        greater influence than neighbors which are further away.\n",
            " |      - [callable] : a user-defined function which accepts an\n",
            " |        array of distances, and returns an array of the same shape\n",
            " |        containing the weights.\n",
            " |\n",
            " |      Refer to the example entitled\n",
            " |      :ref:`sphx_glr_auto_examples_neighbors_plot_classification.py`\n",
            " |      showing the impact of the `weights` parameter on the decision\n",
            " |      boundary.\n",
            " |\n",
            " |  algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'\n",
            " |      Algorithm used to compute the nearest neighbors:\n",
            " |\n",
            " |      - 'ball_tree' will use :class:`BallTree`\n",
            " |      - 'kd_tree' will use :class:`KDTree`\n",
            " |      - 'brute' will use a brute-force search.\n",
            " |      - 'auto' will attempt to decide the most appropriate algorithm\n",
            " |        based on the values passed to :meth:`fit` method.\n",
            " |\n",
            " |      Note: fitting on sparse input will override the setting of\n",
            " |      this parameter, using brute force.\n",
            " |\n",
            " |  leaf_size : int, default=30\n",
            " |      Leaf size passed to BallTree or KDTree.  This can affect the\n",
            " |      speed of the construction and query, as well as the memory\n",
            " |      required to store the tree.  The optimal value depends on the\n",
            " |      nature of the problem.\n",
            " |\n",
            " |  p : float, default=2\n",
            " |      Power parameter for the Minkowski metric. When p = 1, this is equivalent\n",
            " |      to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2.\n",
            " |      For arbitrary p, minkowski_distance (l_p) is used. This parameter is expected\n",
            " |      to be positive.\n",
            " |\n",
            " |  metric : str or callable, default='minkowski'\n",
            " |      Metric to use for distance computation. Default is \"minkowski\", which\n",
            " |      results in the standard Euclidean distance when p = 2. See the\n",
            " |      documentation of `scipy.spatial.distance\n",
            " |      <https://docs.scipy.org/doc/scipy/reference/spatial.distance.html>`_ and\n",
            " |      the metrics listed in\n",
            " |      :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric\n",
            " |      values.\n",
            " |\n",
            " |      If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
            " |      must be square during fit. X may be a :term:`sparse graph`, in which\n",
            " |      case only \"nonzero\" elements may be considered neighbors.\n",
            " |\n",
            " |      If metric is a callable function, it takes two arrays representing 1D\n",
            " |      vectors as inputs and must return one value indicating the distance\n",
            " |      between those vectors. This works for Scipy's metrics, but is less\n",
            " |      efficient than passing the metric name as a string.\n",
            " |\n",
            " |  metric_params : dict, default=None\n",
            " |      Additional keyword arguments for the metric function.\n",
            " |\n",
            " |  n_jobs : int, default=None\n",
            " |      The number of parallel jobs to run for neighbors search.\n",
            " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
            " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
            " |      for more details.\n",
            " |      Doesn't affect :meth:`fit` method.\n",
            " |\n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  classes_ : array of shape (n_classes,)\n",
            " |      Class labels known to the classifier\n",
            " |\n",
            " |  effective_metric_ : str or callble\n",
            " |      The distance metric used. It will be same as the `metric` parameter\n",
            " |      or a synonym of it, e.g. 'euclidean' if the `metric` parameter set to\n",
            " |      'minkowski' and `p` parameter set to 2.\n",
            " |\n",
            " |  effective_metric_params_ : dict\n",
            " |      Additional keyword arguments for the metric function. For most metrics\n",
            " |      will be same with `metric_params` parameter, but may also contain the\n",
            " |      `p` parameter value if the `effective_metric_` attribute is set to\n",
            " |      'minkowski'.\n",
            " |\n",
            " |  n_features_in_ : int\n",
            " |      Number of features seen during :term:`fit`.\n",
            " |\n",
            " |      .. versionadded:: 0.24\n",
            " |\n",
            " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
            " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
            " |      has feature names that are all strings.\n",
            " |\n",
            " |      .. versionadded:: 1.0\n",
            " |\n",
            " |  n_samples_fit_ : int\n",
            " |      Number of samples in the fitted data.\n",
            " |\n",
            " |  outputs_2d_ : bool\n",
            " |      False when `y`'s shape is (n_samples, ) or (n_samples, 1) during fit\n",
            " |      otherwise True.\n",
            " |\n",
            " |  See Also\n",
            " |  --------\n",
            " |  RadiusNeighborsClassifier: Classifier based on neighbors within a fixed radius.\n",
            " |  KNeighborsRegressor: Regression based on k-nearest neighbors.\n",
            " |  RadiusNeighborsRegressor: Regression based on neighbors within a fixed radius.\n",
            " |  NearestNeighbors: Unsupervised learner for implementing neighbor searches.\n",
            " |\n",
            " |  Notes\n",
            " |  -----\n",
            " |  See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
            " |  for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
            " |\n",
            " |  .. warning::\n",
            " |\n",
            " |     Regarding the Nearest Neighbors algorithms, if it is found that two\n",
            " |     neighbors, neighbor `k+1` and `k`, have identical distances\n",
            " |     but different labels, the results will depend on the ordering of the\n",
            " |     training data.\n",
            " |\n",
            " |  https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n",
            " |\n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> X = [[0], [1], [2], [3]]\n",
            " |  >>> y = [0, 0, 1, 1]\n",
            " |  >>> from sklearn.neighbors import KNeighborsClassifier\n",
            " |  >>> neigh = KNeighborsClassifier(n_neighbors=3)\n",
            " |  >>> neigh.fit(X, y)\n",
            " |  KNeighborsClassifier(...)\n",
            " |  >>> print(neigh.predict([[1.1]]))\n",
            " |  [0]\n",
            " |  >>> print(neigh.predict_proba([[0.9]]))\n",
            " |  [[0.666... 0.333...]]\n",
            " |\n",
            " |  Method resolution order:\n",
            " |      KNeighborsClassifier\n",
            " |      sklearn.neighbors._base.KNeighborsMixin\n",
            " |      sklearn.base.ClassifierMixin\n",
            " |      sklearn.neighbors._base.NeighborsBase\n",
            " |      sklearn.base.MultiOutputMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
            " |      sklearn.utils._metadata_requests._MetadataRequester\n",
            " |      builtins.object\n",
            " |\n",
            " |  Methods defined here:\n",
            " |\n",
            " |  __init__(self, n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |\n",
            " |  __sklearn_tags__(self)\n",
            " |\n",
            " |  fit(self, X, y)\n",
            " |      Fit the k-nearest neighbors classifier from the training dataset.\n",
            " |\n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples, n_samples) if metric='precomputed'\n",
            " |          Training data.\n",
            " |\n",
            " |      y : {array-like, sparse matrix} of shape (n_samples,) or                 (n_samples, n_outputs)\n",
            " |          Target values.\n",
            " |\n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : KNeighborsClassifier\n",
            " |          The fitted k-nearest neighbors classifier.\n",
            " |\n",
            " |  predict(self, X)\n",
            " |      Predict the class labels for the provided data.\n",
            " |\n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed', or None\n",
            " |          Test samples. If `None`, predictions for all indexed points are\n",
            " |          returned; in this case, points are not considered their own\n",
            " |          neighbors.\n",
            " |\n",
            " |      Returns\n",
            " |      -------\n",
            " |      y : ndarray of shape (n_queries,) or (n_queries, n_outputs)\n",
            " |          Class labels for each data sample.\n",
            " |\n",
            " |  predict_proba(self, X)\n",
            " |      Return probability estimates for the test data X.\n",
            " |\n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed', or None\n",
            " |          Test samples. If `None`, predictions for all indexed points are\n",
            " |          returned; in this case, points are not considered their own\n",
            " |          neighbors.\n",
            " |\n",
            " |      Returns\n",
            " |      -------\n",
            " |      p : ndarray of shape (n_queries, n_classes), or a list of n_outputs                 of such arrays if n_outputs > 1.\n",
            " |          The class probabilities of the input samples. Classes are ordered\n",
            " |          by lexicographic order.\n",
            " |\n",
            " |  score(self, X, y, sample_weight=None)\n",
            " |      Return the mean accuracy on the given test data and labels.\n",
            " |\n",
            " |      In multi-label classification, this is the subset accuracy\n",
            " |      which is a harsh metric since you require for each sample that\n",
            " |      each label set be correctly predicted.\n",
            " |\n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features), or None\n",
            " |          Test samples. If `None`, predictions for all indexed points are\n",
            " |          used; in this case, points are not considered their own\n",
            " |          neighbors. This means that `knn.fit(X, y).score(None, y)`\n",
            " |          implicitly performs a leave-one-out cross-validation procedure\n",
            " |          and is equivalent to `cross_val_score(knn, X, y, cv=LeaveOneOut())`\n",
            " |          but typically much faster.\n",
            " |\n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          True labels for `X`.\n",
            " |\n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights.\n",
            " |\n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
            " |\n",
            " |  set_score_request(self: sklearn.neighbors._classification.KNeighborsClassifier, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.neighbors._classification.KNeighborsClassifier from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
            " |      Request metadata passed to the ``score`` method.\n",
            " |\n",
            " |      Note that this method is only relevant if\n",
            " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
            " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
            " |      mechanism works.\n",
            " |\n",
            " |      The options for each parameter are:\n",
            " |\n",
            " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
            " |\n",
            " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
            " |\n",
            " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
            " |\n",
            " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
            " |\n",
            " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
            " |      existing request. This allows you to change the request for some\n",
            " |      parameters and not others.\n",
            " |\n",
            " |      .. versionadded:: 1.3\n",
            " |\n",
            " |      .. note::\n",
            " |          This method is only relevant if this estimator is used as a\n",
            " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
            " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
            " |\n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
            " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
            " |\n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          The updated object.\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |\n",
            " |  __abstractmethods__ = frozenset()\n",
            " |\n",
            " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.neighbors._base.KNeighborsMixin:\n",
            " |\n",
            " |  kneighbors(self, X=None, n_neighbors=None, return_distance=True)\n",
            " |      Find the K-neighbors of a point.\n",
            " |\n",
            " |      Returns indices of and distances to the neighbors of each point.\n",
            " |\n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix}, shape (n_queries, n_features),             or (n_queries, n_indexed) if metric == 'precomputed', default=None\n",
            " |          The query point or points.\n",
            " |          If not provided, neighbors of each indexed point are returned.\n",
            " |          In this case, the query point is not considered its own neighbor.\n",
            " |\n",
            " |      n_neighbors : int, default=None\n",
            " |          Number of neighbors required for each sample. The default is the\n",
            " |          value passed to the constructor.\n",
            " |\n",
            " |      return_distance : bool, default=True\n",
            " |          Whether or not to return the distances.\n",
            " |\n",
            " |      Returns\n",
            " |      -------\n",
            " |      neigh_dist : ndarray of shape (n_queries, n_neighbors)\n",
            " |          Array representing the lengths to points, only present if\n",
            " |          return_distance=True.\n",
            " |\n",
            " |      neigh_ind : ndarray of shape (n_queries, n_neighbors)\n",
            " |          Indices of the nearest points in the population matrix.\n",
            " |\n",
            " |      Examples\n",
            " |      --------\n",
            " |      In the following example, we construct a NearestNeighbors\n",
            " |      class from an array representing our data set and ask who's\n",
            " |      the closest point to [1,1,1]\n",
            " |\n",
            " |      >>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n",
            " |      >>> from sklearn.neighbors import NearestNeighbors\n",
            " |      >>> neigh = NearestNeighbors(n_neighbors=1)\n",
            " |      >>> neigh.fit(samples)\n",
            " |      NearestNeighbors(n_neighbors=1)\n",
            " |      >>> print(neigh.kneighbors([[1., 1., 1.]]))\n",
            " |      (array([[0.5]]), array([[2]]))\n",
            " |\n",
            " |      As you can see, it returns [[0.5]], and [[2]], which means that the\n",
            " |      element is at distance 0.5 and is the third element of samples\n",
            " |      (indexes start at 0). You can also query for multiple points:\n",
            " |\n",
            " |      >>> X = [[0., 1., 0.], [1., 0., 1.]]\n",
            " |      >>> neigh.kneighbors(X, return_distance=False)\n",
            " |      array([[1],\n",
            " |             [2]]...)\n",
            " |\n",
            " |  kneighbors_graph(self, X=None, n_neighbors=None, mode='connectivity')\n",
            " |      Compute the (weighted) graph of k-Neighbors for points in X.\n",
            " |\n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_queries, n_features),             or (n_queries, n_indexed) if metric == 'precomputed', default=None\n",
            " |          The query point or points.\n",
            " |          If not provided, neighbors of each indexed point are returned.\n",
            " |          In this case, the query point is not considered its own neighbor.\n",
            " |          For ``metric='precomputed'`` the shape should be\n",
            " |          (n_queries, n_indexed). Otherwise the shape should be\n",
            " |          (n_queries, n_features).\n",
            " |\n",
            " |      n_neighbors : int, default=None\n",
            " |          Number of neighbors for each sample. The default is the value\n",
            " |          passed to the constructor.\n",
            " |\n",
            " |      mode : {'connectivity', 'distance'}, default='connectivity'\n",
            " |          Type of returned matrix: 'connectivity' will return the\n",
            " |          connectivity matrix with ones and zeros, in 'distance' the\n",
            " |          edges are distances between points, type of distance\n",
            " |          depends on the selected metric parameter in\n",
            " |          NearestNeighbors class.\n",
            " |\n",
            " |      Returns\n",
            " |      -------\n",
            " |      A : sparse-matrix of shape (n_queries, n_samples_fit)\n",
            " |          `n_samples_fit` is the number of samples in the fitted data.\n",
            " |          `A[i, j]` gives the weight of the edge connecting `i` to `j`.\n",
            " |          The matrix is of CSR format.\n",
            " |\n",
            " |      See Also\n",
            " |      --------\n",
            " |      NearestNeighbors.radius_neighbors_graph : Compute the (weighted) graph\n",
            " |          of Neighbors for points in X.\n",
            " |\n",
            " |      Examples\n",
            " |      --------\n",
            " |      >>> X = [[0], [3], [1]]\n",
            " |      >>> from sklearn.neighbors import NearestNeighbors\n",
            " |      >>> neigh = NearestNeighbors(n_neighbors=2)\n",
            " |      >>> neigh.fit(X)\n",
            " |      NearestNeighbors(n_neighbors=2)\n",
            " |      >>> A = neigh.kneighbors_graph(X)\n",
            " |      >>> A.toarray()\n",
            " |      array([[1., 0., 1.],\n",
            " |             [0., 1., 1.],\n",
            " |             [1., 0., 1.]])\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.neighbors._base.KNeighborsMixin:\n",
            " |\n",
            " |  __dict__\n",
            " |      dictionary for instance variables\n",
            " |\n",
            " |  __weakref__\n",
            " |      list of weak references to the object\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |\n",
            " |  __getstate__(self)\n",
            " |      Helper for pickle.\n",
            " |\n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |\n",
            " |  __setstate__(self, state)\n",
            " |\n",
            " |  __sklearn_clone__(self)\n",
            " |\n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |\n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |\n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : dict\n",
            " |          Parameter names mapped to their values.\n",
            " |\n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |\n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
            " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
            " |      possible to update each component of a nested object.\n",
            " |\n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |\n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : estimator instance\n",
            " |          Estimator instance.\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            " |\n",
            " |  get_metadata_routing(self)\n",
            " |      Get metadata routing of this object.\n",
            " |\n",
            " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
            " |      mechanism works.\n",
            " |\n",
            " |      Returns\n",
            " |      -------\n",
            " |      routing : MetadataRequest\n",
            " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
            " |          routing information.\n",
            " |\n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
            " |\n",
            " |  __init_subclass__(**kwargs)\n",
            " |      Set the ``set_{method}_request`` methods.\n",
            " |\n",
            " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
            " |      looks for the information available in the set default values which are\n",
            " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
            " |      from method signatures.\n",
            " |\n",
            " |      The ``__metadata_request__*`` class attributes are used when a method\n",
            " |      does not explicitly accept a metadata through its arguments or if the\n",
            " |      developer would like to specify a request value for those metadata\n",
            " |      which are different from the default ``None``.\n",
            " |\n",
            " |      References\n",
            " |      ----------\n",
            " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the following code to generate an artificial dataset which contain three classes. Conduct a similar KNN analysis to the dataset and report your accuracy."
      ],
      "metadata": {
        "id": "tws-xX2F5WH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "centers = [[2, 4], [6, 6], [1, 9]]\n",
        "n_classes = len(centers)\n",
        "data, labels = make_blobs(n_samples=10000,\n",
        "                          centers=np.array(centers),\n",
        "                          random_state=3)\n",
        "# do a 80-20 split of the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "res = train_test_split(data, labels,\n",
        "                       train_size=0.8,\n",
        "                       test_size=0.2,\n",
        "                       random_state=148)\n",
        "train_data, test_data, train_labels, test_labels = res\n",
        "\n",
        "# perform a KNN analysis of the simulated data\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# classifier \"out of the box\", no parameters\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(train_data, train_labels)\n",
        "\n",
        "# print some metrics for \"out of the box\" KNN classifier\n",
        "print(\"Predictions from the classifier (no parameter changes):\")\n",
        "learn_data_predicted = knn.predict(train_data)\n",
        "print(learn_data_predicted)\n",
        "\n",
        "print(\"Target values:\")\n",
        "print(train_labels)\n",
        "print(accuracy_score(learn_data_predicted, train_labels))\n",
        "\n",
        "test_data_predicted = knn.predict(test_data)\n",
        "print(accuracy_score(test_data_predicted, test_labels))\n",
        "\n",
        "#doing the analysis again using different parameters\n",
        "\n",
        "# classifier with new parameters\n",
        "knn2 = KNeighborsClassifier(algorithm='ball_tree',\n",
        "                            leaf_size=20,\n",
        "                            metric='minkowski',\n",
        "                            p=2,         # p=2 is equivalent to euclidian distance\n",
        "                            metric_params=None,\n",
        "                            n_jobs=1,\n",
        "                            n_neighbors=5,\n",
        "                            weights='distance')\n",
        "knn2.fit(train_data, train_labels)\n",
        "\n",
        "# print some interested metrics\n",
        "print(\"Predictions from the classifier (with parameter changes):\")\n",
        "learn2_data_predicted = knn2.predict(train_data)\n",
        "print(learn2_data_predicted)\n",
        "\n",
        "print(\"Target values:\")\n",
        "print(train_labels)\n",
        "print(accuracy_score(learn2_data_predicted, train_labels))\n",
        "\n",
        "test2_data_predicted = knn2.predict(test_data)\n",
        "print(accuracy_score(test2_data_predicted, test_labels))\n",
        "\n",
        "\n",
        "# plot your different results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38ae86f9-3c99-472c-cec0-a14f9adcc254",
        "id": "pxWKZlw6aCne"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions from the classifier (no parameter changes):\n",
            "[2 0 2 ... 2 1 0]\n",
            "Target values:\n",
            "[2 0 2 ... 2 1 0]\n",
            "0.99025\n",
            "0.985\n",
            "Predictions from the classifier (with parameter changes):\n",
            "[2 0 2 ... 2 1 0]\n",
            "Target values:\n",
            "[2 0 2 ... 2 1 0]\n",
            "1.0\n",
            "0.9855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above code, I calculated the differences between the accuracy scores of the KNN classifier that had automatically selected values, versus the custom parameters in the second KNN classifier. With a large sample size, the auto selected KNN classifier was more accurate."
      ],
      "metadata": {
        "id": "BzKuiOtn4niF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F7-6NH-UdcI9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}